{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd22f84a-a20b-44ef-be0a-295579d69841",
   "metadata": {},
   "source": [
    "# Basic Neural Net from scratch\n",
    "\n",
    "This notebook has the purpose of creating a simple neural net from scratch only wiht pytorch. \n",
    "\n",
    "To do this, I need: \n",
    " - linear\n",
    " - Relu\n",
    " - sigmoid\n",
    " - softmax\n",
    " - backwards, i.e. the parameters, gradients\n",
    " - some kind of loss function, MSE, RMSE? - cross entropy loss it is\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa2179-261e-4370-a7e2-df17f8fd4581",
   "metadata": {},
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = create_params([n_users, n_factors])\n",
    "        self.user_bias = create_params([n_users])\n",
    "        self.movie_factors = create_params([n_movies, n_factors])\n",
    "        self.movie_bias = create_params([n_movies])\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors[x[:,0]]\n",
    "        movies = self.movie_factors[x[:,1]]\n",
    "        res = (users*movies).sum(dim=1)\n",
    "        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
    "        return sigmoid_range(res, *self.y_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64cfae2-71ac-447e-8221-44dbfdea4339",
   "metadata": {},
   "source": [
    "before doing the model - do not forget to clean the data and transform it so that most of the variation is between 0 and 1.\n",
    "\n",
    "With e.g. divide it by its maximum, so that it becomes like a percentage or use a sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f1a17-650c-4ccf-a580-4db90d945680",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## import data and shift it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa65df41-096e-4377-a1b8-49d364666c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11716, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.06.01 00:00</td>\n",
       "      <td>27103.1</td>\n",
       "      <td>27108.1</td>\n",
       "      <td>27080.6</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>386.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.06.01 00:15</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>408.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.06.01 00:30</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>275.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time     open     high      low    close      vol\n",
       "0  2023.06.01 00:00  27103.1  27108.1  27080.6  27096.9  386.675\n",
       "1  2023.06.01 00:15  27096.9  27096.9  27036.7  27047.0  408.680\n",
       "2  2023.06.01 00:30  27047.0  27077.4  27041.0  27054.9  275.080"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "if iskaggle:\n",
    "    df = pd.read_csv(\"/kaggle/input/btcusdt-2023-6-9/btcusdt-2023-6_9.csv\", index_col=0).reset_index(drop=True)\n",
    "else:\n",
    "    df = pd.read_csv(\"lesson5-random-forests/btc-data/btcusdt-2023-6_9.csv\", index_col=0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343bc4a7-f50e-4597-9f35-13d48dae69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11716, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_s3</th>\n",
       "      <th>open_s3</th>\n",
       "      <th>high_s3</th>\n",
       "      <th>low_s3</th>\n",
       "      <th>close_s3</th>\n",
       "      <th>vol_s3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_s3  open_s3  high_s3  low_s3  close_s3  vol_s3\n",
       "0    None      NaN      NaN     NaN       NaN     NaN\n",
       "1    None      NaN      NaN     NaN       NaN     NaN\n",
       "2    None      NaN      NaN     NaN       NaN     NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift data 3 times, so that in one row there is information on the last 3 candles \n",
    "# therefore: the original candle data is the target data\n",
    "\n",
    "df_s1 = df.shift(1).add_suffix(\"_s1\")\n",
    "df_s2 = df.shift(2).add_suffix(\"_s2\")\n",
    "df_s3 = df.shift(3).add_suffix(\"_s3\")\n",
    "\n",
    "print(df_s3.shape)\n",
    "df_s3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6390808-5b94-40ca-924f-50a3c6d0b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11716, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_s3</th>\n",
       "      <th>open_s3</th>\n",
       "      <th>high_s3</th>\n",
       "      <th>low_s3</th>\n",
       "      <th>close_s3</th>\n",
       "      <th>vol_s3</th>\n",
       "      <th>time_s2</th>\n",
       "      <th>open_s2</th>\n",
       "      <th>high_s2</th>\n",
       "      <th>low_s2</th>\n",
       "      <th>...</th>\n",
       "      <th>high_s1</th>\n",
       "      <th>low_s1</th>\n",
       "      <th>close_s1</th>\n",
       "      <th>vol_s1</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023.06.01 00:00</td>\n",
       "      <td>27103.1</td>\n",
       "      <td>27108.1</td>\n",
       "      <td>27080.6</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>386.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27108.1</td>\n",
       "      <td>27080.6</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>386.675</td>\n",
       "      <td>2023.06.01 00:15</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>408.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023.06.01 00:00</td>\n",
       "      <td>27103.1</td>\n",
       "      <td>27108.1</td>\n",
       "      <td>27080.6</td>\n",
       "      <td>...</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>408.680</td>\n",
       "      <td>2023.06.01 00:30</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>275.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.06.01 00:00</td>\n",
       "      <td>27103.1</td>\n",
       "      <td>27108.1</td>\n",
       "      <td>27080.6</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>386.675</td>\n",
       "      <td>2023.06.01 00:15</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>...</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>275.080</td>\n",
       "      <td>2023.06.01 00:45</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27054.8</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>218.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.06.01 00:15</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>408.680</td>\n",
       "      <td>2023.06.01 00:30</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27054.8</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>218.143</td>\n",
       "      <td>2023.06.01 01:00</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27113.9</td>\n",
       "      <td>27073.5</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>329.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_s3  open_s3  high_s3   low_s3  close_s3   vol_s3  \\\n",
       "0              None      NaN      NaN      NaN       NaN      NaN   \n",
       "1              None      NaN      NaN      NaN       NaN      NaN   \n",
       "2              None      NaN      NaN      NaN       NaN      NaN   \n",
       "3  2023.06.01 00:00  27103.1  27108.1  27080.6   27096.9  386.675   \n",
       "4  2023.06.01 00:15  27096.9  27096.9  27036.7   27047.0  408.680   \n",
       "\n",
       "            time_s2  open_s2  high_s2   low_s2  ...  high_s1   low_s1  \\\n",
       "0              None      NaN      NaN      NaN  ...      NaN      NaN   \n",
       "1              None      NaN      NaN      NaN  ...  27108.1  27080.6   \n",
       "2  2023.06.01 00:00  27103.1  27108.1  27080.6  ...  27096.9  27036.7   \n",
       "3  2023.06.01 00:15  27096.9  27096.9  27036.7  ...  27077.4  27041.0   \n",
       "4  2023.06.01 00:30  27047.0  27077.4  27041.0  ...  27084.0  27054.8   \n",
       "\n",
       "  close_s1   vol_s1              time     open     high      low    close  \\\n",
       "0      NaN      NaN  2023.06.01 00:00  27103.1  27108.1  27080.6  27096.9   \n",
       "1  27096.9  386.675  2023.06.01 00:15  27096.9  27096.9  27036.7  27047.0   \n",
       "2  27047.0  408.680  2023.06.01 00:30  27047.0  27077.4  27041.0  27054.9   \n",
       "3  27054.9  275.080  2023.06.01 00:45  27054.9  27084.0  27054.8  27084.0   \n",
       "4  27084.0  218.143  2023.06.01 01:00  27084.0  27113.9  27073.5  27100.0   \n",
       "\n",
       "       vol  \n",
       "0  386.675  \n",
       "1  408.680  \n",
       "2  275.080  \n",
       "3  218.143  \n",
       "4  329.412  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.concat([df_s3,df_s2, df_s1, df], axis=1)\n",
    "print(df_merge.shape)\n",
    "df_merge.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2000e02-351c-4659-bb09-f62d5ae569eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_s3', 'open_s3', 'high_s3', 'low_s3', 'close_s3', 'vol_s3',\n",
       "       'time_s2', 'open_s2', 'high_s2', 'low_s2', 'close_s2', 'vol_s2',\n",
       "       'time_s1', 'open_s1', 'high_s1', 'low_s1', 'close_s1', 'vol_s1', 'time',\n",
       "       'open', 'high', 'low', 'close', 'vol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0efb72-f035-4dbb-aedc-074c5c4042ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11713, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_s3</th>\n",
       "      <th>high_s3</th>\n",
       "      <th>low_s3</th>\n",
       "      <th>close_s3</th>\n",
       "      <th>vol_s3</th>\n",
       "      <th>open_s2</th>\n",
       "      <th>high_s2</th>\n",
       "      <th>low_s2</th>\n",
       "      <th>close_s2</th>\n",
       "      <th>vol_s2</th>\n",
       "      <th>open_s1</th>\n",
       "      <th>high_s1</th>\n",
       "      <th>low_s1</th>\n",
       "      <th>close_s1</th>\n",
       "      <th>vol_s1</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27103.1</td>\n",
       "      <td>27108.1</td>\n",
       "      <td>27080.6</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>386.675</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>408.680</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>275.080</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27054.8</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>218.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27096.9</td>\n",
       "      <td>27096.9</td>\n",
       "      <td>27036.7</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>408.680</td>\n",
       "      <td>27047.0</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>275.080</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27054.8</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>218.143</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27113.9</td>\n",
       "      <td>27073.5</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>329.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27047.0</td>\n",
       "      <td>27077.4</td>\n",
       "      <td>27041.0</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>275.080</td>\n",
       "      <td>27054.9</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27054.8</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>218.143</td>\n",
       "      <td>27084.0</td>\n",
       "      <td>27113.9</td>\n",
       "      <td>27073.5</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>329.412</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>27159.0</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>27142.4</td>\n",
       "      <td>979.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   open_s3  high_s3   low_s3  close_s3   vol_s3  open_s2  high_s2   low_s2  \\\n",
       "3  27103.1  27108.1  27080.6   27096.9  386.675  27096.9  27096.9  27036.7   \n",
       "4  27096.9  27096.9  27036.7   27047.0  408.680  27047.0  27077.4  27041.0   \n",
       "5  27047.0  27077.4  27041.0   27054.9  275.080  27054.9  27084.0  27054.8   \n",
       "\n",
       "   close_s2   vol_s2  open_s1  high_s1   low_s1  close_s1   vol_s1     open  \\\n",
       "3   27047.0  408.680  27047.0  27077.4  27041.0   27054.9  275.080  27054.9   \n",
       "4   27054.9  275.080  27054.9  27084.0  27054.8   27084.0  218.143  27084.0   \n",
       "5   27084.0  218.143  27084.0  27113.9  27073.5   27100.0  329.412  27100.0   \n",
       "\n",
       "      high      low    close      vol  \n",
       "3  27084.0  27054.8  27084.0  218.143  \n",
       "4  27113.9  27073.5  27100.0  329.412  \n",
       "5  27159.0  27100.0  27142.4  979.655  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not use the time columns \n",
    "\n",
    "df_train = df_merge.filter(items = ['open_s3', 'high_s3', 'low_s3', 'close_s3', 'vol_s3',\n",
    "       'open_s2', 'high_s2', 'low_s2', 'close_s2', 'vol_s2',\n",
    "       'open_s1', 'high_s1', 'low_s1', 'close_s1', 'vol_s1', \n",
    "       'open', 'high', 'low', 'close', 'vol']).dropna()\n",
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da202235-e6bb-4e45-8a68-f62191d17acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train\n",
    "#df_train.filter(items = [\"open_s3\"])\n",
    "#df_train.loc[[\"open_s3\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f80f7-7005-4c31-9ca1-4bb869c8ab82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# fastai neural net from scratch\n",
    "\n",
    "https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23dbbac0-4b96-4eda-8eb2-6717c2d3bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3211d88a-6139-4a62-856e-62d55b2421fa",
   "metadata": {},
   "source": [
    "from https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
    "\n",
    "\"PyTorch provides methods to create random or zero-filled tensors, which we will use to create our weights and bias for a simple linear model. These are just regular tensors, with one very special addition: we tell PyTorch that they require a gradient. **This causes PyTorch to record all of the operations done on the tensor, so that it can calculate the gradient during back-propagation automatically!**\n",
    "\n",
    "For the weights, we set requires_grad after the initialization, since we don’t want that step included in the gradient. (Note that a trailing _ in PyTorch signifies that the operation is performed in-place.)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29835d73-af68-4ca8-b034-f422079fbed2",
   "metadata": {},
   "source": [
    "## dep, indep & weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698cabc-d81f-488b-9b08-0da27f972a43",
   "metadata": {},
   "source": [
    "In this setting we will just try to predict the high value based on the previous three candles. The results will likely not be good since point predictions are tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d57916-3ed2-410d-8188-8b548d2e15f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11713])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([27084.0000, 27113.9004, 27159.0000,  ..., 27058.1992, 27061.1992,\n",
       "        27066.6992])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dep = tensor(df_train['high'].values, dtype=torch.float)\n",
    "print(t_dep.shape) # 1 D tensor\n",
    "t_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0297673-ad3b-44eb-8cf0-298ee966f5d0",
   "metadata": {},
   "source": [
    "All variables are used instead of the high value which is the dependend value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdfb70a0-a12d-40f8-b6bc-d2a59badc2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11713, 19])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep = tensor(df_train.loc[:, df_train.columns != \"high\"].values, dtype=torch.float)\n",
    "\n",
    "t_indep.shape # 2 D tensor > rows with observations and columns with features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97af7f-e8a3-4116-a8fe-b00eb218cf5f",
   "metadata": {},
   "source": [
    "The number of features needs to be the same as the lenght of the weights, because they will be multiplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df6b332-1450-4dc1-bafb-036358841e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "n,c = t_indep.shape\n",
    "\n",
    "# \"We are initializing the weights here with Xavier initialisation (by multiplying with 1/sqrt(n)).\"\n",
    "weights = torch.randn(c) / math.sqrt(n)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(n, requires_grad=True)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22ac892-c9b8-4286-a122-d1fd36b91dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5784e+02, -4.4804e+01,  1.3625e+02,  ..., -9.5710e+01,\n",
       "          3.6488e+02, -7.2410e-02],\n",
       "        [ 2.5778e+02, -4.4785e+01,  1.3603e+02,  ..., -9.5776e+01,\n",
       "          3.6509e+02, -1.0934e-01],\n",
       "        [ 2.5730e+02, -4.4753e+01,  1.3605e+02,  ..., -9.5870e+01,\n",
       "          3.6566e+02, -3.2518e-01],\n",
       "        ...,\n",
       "        [ 2.5709e+02, -4.4667e+01,  1.3589e+02,  ..., -9.5576e+01,\n",
       "          3.6452e+02, -6.5783e-02],\n",
       "        [ 2.5697e+02, -4.4688e+01,  1.3590e+02,  ..., -9.5682e+01,\n",
       "          3.6448e+02, -6.0421e-02],\n",
       "        [ 2.5711e+02, -4.4698e+01,  1.3592e+02,  ..., -9.5709e+01,\n",
       "          3.6464e+02, -7.5299e-02]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da184691-85e6-410a-a142-e7a85716df6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sidebar: torch.randn\n",
    "short check of the torch.randn function: https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e73f77-a591-480c-9a46-e05b4460ad2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2629,  0.3949,  0.1772,  0.3931, -0.6135,  1.4620,  0.5037,  0.4781,\n",
       "         -0.3800,  0.9131],\n",
       "        [ 1.5714,  1.6454,  1.8434, -1.2316,  1.4499,  0.0425, -0.6158,  0.7689,\n",
       "          0.5111,  1.7750],\n",
       "        [-0.4827,  0.7573,  0.6069, -0.9836, -0.8243, -0.2080,  0.3320, -0.0388,\n",
       "          0.7955, -0.6972],\n",
       "        [-0.6047,  0.9427,  1.1139,  0.2379,  1.2735,  0.0436,  1.4785, -0.1974,\n",
       "         -0.1995,  0.0701],\n",
       "        [ 1.4937, -1.3698,  1.1514,  1.2670,  0.4267, -0.8906,  0.5688, -1.0516,\n",
       "          1.2847,  0.3744],\n",
       "        [-0.8127, -0.6426, -0.3871,  0.0048, -0.7318,  0.8114, -0.4377,  0.1703,\n",
       "          0.9767, -0.6101],\n",
       "        [ 0.4031, -1.1360, -0.7706, -1.0937, -1.2608,  1.0873, -0.2856,  0.5030,\n",
       "          0.8613, -0.5208],\n",
       "        [ 0.6159, -1.6401, -0.5317,  0.6502, -0.1975, -0.9155,  0.9679, -0.4870,\n",
       "          1.0505, -0.7849],\n",
       "        [ 0.3731,  0.5211,  1.5561,  0.1373, -0.1502, -0.1318,  0.5729,  0.3775,\n",
       "          0.8752, -0.1949],\n",
       "        [ 0.2111,  0.9889, -1.0534, -0.1605,  0.7487, -1.0196, -0.8508, -0.6793,\n",
       "         -0.1088,  0.6824],\n",
       "        [ 2.3033,  0.8157, -0.0144, -0.6515, -0.1964, -0.3208,  0.6814, -1.4209,\n",
       "          0.4274, -0.0329],\n",
       "        [-0.5561, -1.5578, -0.2725, -1.6431,  0.9852, -0.2271,  0.4428, -0.2824,\n",
       "          0.6802,  0.2705],\n",
       "        [ 0.6741,  2.0111,  0.2407,  0.9818,  1.1530,  0.6662, -1.6120,  0.3856,\n",
       "         -0.9074, -1.1703],\n",
       "        [-0.6057,  1.5477,  0.9767,  0.0442, -1.1549, -0.2526,  2.4217,  0.3754,\n",
       "          0.0722,  1.1712],\n",
       "        [ 0.1272,  0.1073, -0.3223, -0.2038,  0.5066,  1.5181,  0.6642, -0.3027,\n",
       "          0.6306,  0.2976],\n",
       "        [-0.5325, -0.1593,  0.7290, -1.2773,  0.2474, -0.5793,  1.0297, -1.9669,\n",
       "          1.5442, -0.6613],\n",
       "        [-0.1994, -0.2875,  0.8337,  0.0193,  2.3095, -0.0087,  1.7726,  1.6060,\n",
       "         -0.8478,  0.6691],\n",
       "        [ 0.7391, -0.1595,  0.2631, -2.3002,  0.1994, -1.1149,  0.8493, -0.0918,\n",
       "         -1.5358,  1.0776],\n",
       "        [-0.6772,  1.5026,  1.2946, -1.5916, -0.0559, -1.0926,  0.1267,  0.3521,\n",
       "          1.1924,  0.0545]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(19, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7340f77f-8119-496d-94cf-7a43f7321768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1709,  0.4184, -0.4363,  0.4141,  0.0068, -0.0100,  0.0282,  0.3260,\n",
       "        -0.4098,  0.1290,  0.0705, -0.0140,  0.4278,  0.4106, -0.0672,  0.2847,\n",
       "        -0.1994,  0.0847, -0.2743])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# coefficients = weights\n",
    "# make them from -0.5 to 0.5 from a normal distribution\n",
    "coeffs = torch.rand( t_indep.shape[1] )-0.5\n",
    "\n",
    "print(coeffs.shape)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d49848d-809b-480c-8748-25a62f5bd7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.6318e+03,  1.1342e+04, -1.1815e+04,  1.1220e+04,  2.6103e+00,\n",
       "        -2.7026e+02,  7.6313e+02,  8.8127e+03, -1.1083e+04,  5.2717e+01,\n",
       "         1.9077e+03, -3.7909e+02,  1.1568e+04,  1.1109e+04, -1.8496e+01,\n",
       "         7.7032e+03, -5.3936e+03,  2.2949e+03, -5.9834e+01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t_indep*coeffs)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9fa5f-6dda-4e60-961a-296953ce85dc",
   "metadata": {},
   "source": [
    "As you can see, there are a lot of numbers up and down, since the prices range roughly from 30k to about 60k. \n",
    "\n",
    "Note to myself: if it does not interfere with cross entropy then I should use log on all prices.\n",
    "cross entropy uses log in its calculations and it depends on the implementation if it does interfere (I guess right now)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a048cbf-1602-4bbb-a19b-b2b85dfcc53b",
   "metadata": {},
   "source": [
    "## making the first prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb0985-8922-4952-b2f7-59ba326b03c9",
   "metadata": {},
   "source": [
    "Since we are making a linear classifier the formula for yhat or the predictions is the sum of the products of coefficients and observations. \n",
    "\n",
    "In other words: \n",
    "\n",
    "$ y = x_0 \\times b_0 + x_1 \\times b_1 $\n",
    "\n",
    "where $x_0$ is the first vector of observations (=features) and $b_0$ is the first coefficient.\n",
    "\n",
    "and then is $y$ the vector with the predictions the same length as the data frame, so this formula can be read \"rowwise\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093a7453-6dd6-490d-b01b-04de3157fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11713])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(42388.0156)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)\n",
    "print(preds.shape) # 1d vector of predictions\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c88e8bee-542c-4f10-b482-6b1f76f39443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27103.0996, 27108.0996, 27080.5996, 27096.9004,   386.6750, 27096.9004,\n",
      "        27096.9004, 27036.6992, 27047.0000,   408.6800, 27047.0000, 27077.4004,\n",
      "        27041.0000, 27054.9004,   275.0800, 27054.9004, 27054.8008, 27084.0000,\n",
      "          218.1430])\n",
      "tensor([ 0.1709,  0.4184, -0.4363,  0.4141,  0.0068, -0.0100,  0.0282,  0.3260,\n",
      "        -0.4098,  0.1290,  0.0705, -0.0140,  0.4278,  0.4106, -0.0672,  0.2847,\n",
      "        -0.1994,  0.0847, -0.2743])\n",
      "\n",
      " first entry of Indep * coeffs: \n",
      " tensor(4631.8369)\n",
      "\n",
      " Indep * coeffs: \n",
      " tensor([ 4.6318e+03,  1.1342e+04, -1.1815e+04,  1.1220e+04,  2.6103e+00,\n",
      "        -2.7026e+02,  7.6313e+02,  8.8127e+03, -1.1083e+04,  5.2717e+01,\n",
      "         1.9077e+03, -3.7909e+02,  1.1568e+04,  1.1109e+04, -1.8496e+01,\n",
      "         7.7032e+03, -5.3936e+03,  2.2949e+03, -5.9834e+01])\n",
      "\n",
      " sum of Indep * coeffs: \n",
      " tensor(42388.0156)\n"
     ]
    }
   ],
   "source": [
    "# quick check for first row: \n",
    "\n",
    "print(t_indep[0])\n",
    "print(coeffs)\n",
    "print(\"\\n first entry of Indep * coeffs: \\n\",t_indep[0][0]*coeffs[0])\n",
    "print(\"\\n Indep * coeffs: \\n\",t_indep[0]*coeffs)\n",
    "print(\"\\n sum of Indep * coeffs: \\n\", (t_indep[0]*coeffs).sum() ) #axis=1 is along the colums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20783ec4-6f02-445a-8956-9f8b147e9c9e",
   "metadata": {},
   "source": [
    "## loss: cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3192526-bcce-41f6-a995-2eef783b648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: tensor(2.4529e+08)\n",
      "mean squared error: tensor(2.4529e+08)\n",
      "cross entropy: tensor(2.1783e+12)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_ce = F.cross_entropy(preds, t_dep)\n",
    "loss_mae = F.l1_loss(preds, t_dep)\n",
    "loss_mae = F.mse_loss(preds, t_dep)\n",
    "\n",
    "print(\"mean absolute error:\",loss_mae)\n",
    "print(\"mean squared error:\",loss_mae)\n",
    "print(\"cross entropy:\",loss_ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b03dbf-97f7-42c3-9dbe-9e3cff4afe2b",
   "metadata": {},
   "source": [
    "## gradients & learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185c54b9-b9f5-4890-a5b9-41138163c439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1709,  0.4184, -0.4363,  0.4141,  0.0068, -0.0100,  0.0282,  0.3260,\n",
       "        -0.4098,  0.1290,  0.0705, -0.0140,  0.4278,  0.4106, -0.0672,  0.2847,\n",
       "        -0.1994,  0.0847, -0.2743])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bcd3fc5-81ee-41ea-b66c-0e19384d709d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1709,  0.4184, -0.4363,  0.4141,  0.0068, -0.0100,  0.0282,  0.3260,\n",
       "        -0.4098,  0.1290,  0.0705, -0.0140,  0.4278,  0.4106, -0.0672,  0.2847,\n",
       "        -0.1994,  0.0847, -0.2743], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d627d8b-c09e-45ab-b645-5c64f0d1aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1783e+12, grad_fn=<DivBackward1>)\n",
      "tensor([9.5942e+11, 9.6102e+11, 6.0714e+11, 7.1157e+11, 1.4144e+13, 7.1157e+11,\n",
      "        7.0193e+11, 4.3312e+11, 6.5440e+11, 1.2616e+13, 6.5440e+11, 7.0848e+11,\n",
      "        5.9808e+11, 7.0733e+11, 4.3423e+12, 7.0733e+11, 6.6725e+11, 6.6860e+11,\n",
      "        1.6099e+12])\n"
     ]
    }
   ],
   "source": [
    "# I am not sure if the above way works if I only use the loss functions in a functional style\n",
    "# therefore, I document a way to use it instantiated as a class\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "cel = nn.CrossEntropyLoss()\n",
    "\n",
    "preds = (t_indep*coeffs.requires_grad_()).sum(axis=1)\n",
    "\n",
    "loss = cel(preds,t_dep)\n",
    "print(loss)\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "gradients = coeffs.grad\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5e6e4a4-d0e2-40ab-9698-f9d0283465e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9188e+12, 1.9220e+12, 1.2143e+12, 1.4231e+12, 2.8289e+13, 1.4231e+12,\n",
      "        1.4039e+12, 8.6624e+11, 1.3088e+12, 2.5231e+13, 1.3088e+12, 1.4170e+12,\n",
      "        1.1962e+12, 1.4147e+12, 8.6847e+12, 1.4147e+12, 1.3345e+12, 1.3372e+12,\n",
      "        3.2198e+12])\n"
     ]
    }
   ],
   "source": [
    "loss.backward(retain_graph=True)\n",
    "print(coeffs.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8161a5a0-9d80-4d17-b1fc-060b09f326df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise coeffs and define the independent variable \n",
    "t_indep*coeffs\n",
    "\n",
    "# define it as a function \n",
    "def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "    \n",
    "preds = (t_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2b0bbb9-8ac5-45e2-b72c-a0dd6cd3a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "\n",
    "# herer it is mean absolute error\n",
    "loss = torch.abs(preds-t_dep).mean()\n",
    "\n",
    "# define it in a function\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692b898-df59-48dd-9f98-46e16ccbc215",
   "metadata": {},
   "source": [
    "# next steps\n",
    "\n",
    " - figure out when and how to use backward() and require_grad\n",
    " - put the pieces togehter: calc preds > calc loss > get gradients > subtract gradients*learningrate with preds\n",
    "\n",
    "Note on gradients: \\n\n",
    "My current understand is that you need to specify the tensor of where to calculate the gradients on, to access them explicitly. \\n\n",
    "It seems, that the backward function needs to know the input, target and weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7108317-bba0-4744-a215-1f64cf5e03a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# pytorch beginner tutorial by jeremy howard\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nn_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aec8e12-a769-4f3d-a40e-858956eed9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "xb = torch.randn(64, 784)\n",
    "weights = torch.randn(784, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "587893d9-e412-457e-a254-41a0645a94b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xb@weights\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bd206a9-096d-4a64-af23-032111d4e5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([784, 10])\n"
     ]
    }
   ],
   "source": [
    "print(xb.shape)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e45088-2395-46fd-8ac8-aa5496cbc093",
   "metadata": {},
   "source": [
    "# pytorch basics tutorial\n",
    "see: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4bd45d48-e909-43ef-b3ef-0e4464924c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3039b205-b28d-46b2-bb8a-9360178928ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436632b-c9a6-46d8-a711-d82e0966ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1296832-b559-419b-bda2-8d634f8ca67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc09c76-d517-46e5-8d4d-d96f9e139afe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sidebar: nn.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "523f92d0-4ac2-4f53-b93b-f7f6944d551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = torch.ones(3,2,2)\n",
    "print(input_image.size())\n",
    "\n",
    "input_image[1].add_(1)\n",
    "input_image[2].add_(2)\n",
    "input_image[0,1,1].add_(1)\n",
    "\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64cf2787-9515-432f-a815-7334057284f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "flat_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f6a51b00-0572-4c53-8b68-644f22f15981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear layer shape:torch.Size([3, 2])\n",
      "\n",
      "weight shape:torch.Size([2, 4]) = [out_features,in_features]\n",
      "\n",
      "linear layer weights:\n",
      " Parameter containing:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], requires_grad=True)\n",
      "\n",
      "y=output = \n",
      "tensor([[ 5.,  5.],\n",
      "        [ 8.,  8.],\n",
      "        [12., 12.]], grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  5.],\n",
       "        [ 8.,  8.],\n",
       "        [12., 12.]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "layer1 = nn.Linear(in_features=2*2, out_features=2,bias=False)\n",
    "import torch.nn.init as init\n",
    "init.ones_(layer1.weight)\n",
    "\n",
    "linear_layer = layer1(flat_image)\n",
    "\n",
    "print(f\"\\nlinear layer shape:{linear_layer.size()}\" )\n",
    "w = layer1.weight # has the in_features shape, meaning it is a vector of length 4\n",
    "print(f\"\\nweight shape:{w.shape} = [out_features,in_features]\")\n",
    "print(\"\\nlinear layer weights:\\n\",w)\n",
    "#print(\"\\noutput divided by input\\n\",linear_layer/flat_image)\n",
    "print(f\"\\ny=output = \\n{linear_layer}\")\n",
    "# output should be: \n",
    "flat_image@w.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b88ba2-e368-4e25-9184-d43f9ddd8a70",
   "metadata": {},
   "source": [
    "There for the transformation of $ y = xW^T+b $ where x=in_features, y=out_features, W=weights and b=bias\n",
    "\n",
    " - nn.Linear generates a random weight matrix with shape of [out_features,in_features]\n",
    " - nn.Linear adds all the columns together\n",
    " - the added rows are multiplied with the weight matrix\n",
    " - optionally a bias term is added\n",
    "\n",
    "By summing all input columns a matrix with length of in_features is present to be multiplied with the correct dimension of the weight matrix.\n",
    "\n",
    "see: https://ashwinhprasad.medium.com/pytorch-for-deep-learning-nn-linear-and-nn-relu-explained-77f3e1007dbb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a9b40-bdfb-4a0b-a68d-bd4379428a04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## sidebar: tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be4b72-2fec-47b3-ae7f-2e0e7d408829",
   "metadata": {},
   "source": [
    "One can think of tensors in terms of the below element has an element of 3 which contains 2 elements which contain 4 elements which contain 2 elements, hence resultig in a nested list of two.\n",
    "\n",
    "see also: \n",
    " - https://stackoverflow.com/questions/52370008/understanding-pytorch-tensor-shape\n",
    " - https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e3b9462c-58fc-41e7-b027-899cad9b8ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5035,  0.2602],\n",
       "          [-0.9302,  2.2516],\n",
       "          [-0.4207,  0.4595],\n",
       "          [-0.7512,  0.7634]],\n",
       "\n",
       "         [[-0.5143, -0.5848],\n",
       "          [-0.2461,  1.7794],\n",
       "          [ 0.7803, -1.1677],\n",
       "          [ 3.1528,  0.2449]]],\n",
       "\n",
       "\n",
       "        [[[-0.3602, -0.3408],\n",
       "          [ 0.1743, -0.6936],\n",
       "          [ 0.0032,  1.9898],\n",
       "          [ 0.1117, -1.2837]],\n",
       "\n",
       "         [[-0.5208,  2.4331],\n",
       "          [ 1.5974, -2.6103],\n",
       "          [ 0.6077,  0.5067],\n",
       "          [-0.5647, -1.1774]]],\n",
       "\n",
       "\n",
       "        [[[-0.7844,  0.0668],\n",
       "          [ 0.3072, -0.6778],\n",
       "          [ 0.6296, -2.1064],\n",
       "          [ 0.8055, -0.9905]],\n",
       "\n",
       "         [[-1.4523,  0.6980],\n",
       "          [ 1.5231, -0.2093],\n",
       "          [-0.9006, -0.6028],\n",
       "          [-1.0110, -0.5660]]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.randn(3,2,4,2)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5927880-f03e-4907-9732-061ae6ceeffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7844,  0.0668],\n",
       "         [ 0.3072, -0.6778],\n",
       "         [ 0.6296, -2.1064],\n",
       "         [ 0.8055, -0.9905]],\n",
       "\n",
       "        [[-1.4523,  0.6980],\n",
       "         [ 1.5231, -0.2093],\n",
       "         [-0.9006, -0.6028],\n",
       "         [-1.0110, -0.5660]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the first layer of the tensor consists of three elements of which the third is printed\n",
    "# this third element of the first layer has 2 elements which contain 4 elements which in turn contain 2\n",
    "# the last two form then the vector as printed in the brackets\n",
    "test[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc41621-175e-4ef4-8116-6d0ecdb2bb6e",
   "metadata": {},
   "source": [
    "## next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
